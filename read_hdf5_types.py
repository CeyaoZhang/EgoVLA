#!/usr/bin/env python3
"""
HDF5æ•°æ®ç±»å‹è¯»å–è„šæœ¬
ç”¨äºè¯»å–å’Œæ˜¾ç¤ºHDF5æ–‡ä»¶ä¸­æ‰€æœ‰æ•°æ®é›†çš„ç±»å‹ã€å½¢çŠ¶å’Œå±æ€§ä¿¡æ¯
"""

import h5py
import numpy as np
import argparse
from pathlib import Path


def print_attrs(name, obj, indent=0):
    """æ‰“å°HDF5å¯¹è±¡çš„å±æ€§"""
    prefix = "  " * indent
    if obj.attrs:
        print(f"{prefix}å±æ€§:")
        for key, val in obj.attrs.items():
            print(f"{prefix}  - {key}: {val} (ç±»å‹: {type(val).__name__})")


def print_dataset_info(name, obj, indent=0):
    """æ‰“å°æ•°æ®é›†çš„è¯¦ç»†ä¿¡æ¯"""
    prefix = "  " * indent
    print(f"{prefix}ğŸ“Š æ•°æ®é›†: {name}")
    print(f"{prefix}  â”œâ”€ æ•°æ®ç±»å‹: {obj.dtype}")
    print(f"{prefix}  â”œâ”€ å½¢çŠ¶: {obj.shape}")
    print(f"{prefix}  â”œâ”€ å¤§å°: {obj.size} ä¸ªå…ƒç´ ")
    
    # # å¦‚æœæ•°æ®é›†å¾ˆå°ï¼Œæ˜¾ç¤ºä¸€äº›æ ·æœ¬æ•°æ®
    # if obj.size > 0 and obj.size <= 10:
    #     print(f"{prefix}  â”œâ”€ æ•°æ®: {obj[...]}")
    # elif obj.size > 0:
    #     # æ˜¾ç¤ºç¬¬ä¸€ä¸ªå…ƒç´ ä½œä¸ºæ ·ä¾‹
    #     try:
    #         if len(obj.shape) == 1:
    #             print(f"{prefix}  â”œâ”€ æ ·ä¾‹æ•°æ® (å‰3ä¸ª): {obj[:min(3, obj.shape[0])]}")
    #         else:
    #             print(f"{prefix}  â”œâ”€ æ ·ä¾‹æ•°æ® (é¦–é¡¹): {obj[0]}")
    #     except:
    #         print(f"{prefix}  â”œâ”€ æ ·ä¾‹æ•°æ®: (æ— æ³•è¯»å–)")
    
    # # æ‰“å°å±æ€§
    # if obj.attrs:
    #     print(f"{prefix}  â””â”€ å±æ€§:")
    #     for key, val in obj.attrs.items():
    #         print(f"{prefix}      - {key}: {val}")
    # else:
    #     print(f"{prefix}  â””â”€ (æ— å±æ€§)")


def print_group_info(name, obj, indent=0):
    """æ‰“å°ç»„çš„ä¿¡æ¯"""
    prefix = "  " * indent
    print(f"{prefix}ğŸ“ ç»„: {name if name else 'æ ¹ç›®å½•'}")
    
    # æ‰“å°ç»„çš„å±æ€§
    if obj.attrs:
        print(f"{prefix}  å±æ€§:")
        for key, val in obj.attrs.items():
            print(f"{prefix}    - {key}: {val}")


def explore_hdf5(file_path, show_data=False, max_depth=None):
    """
    é€’å½’éå†HDF5æ–‡ä»¶å¹¶æ‰“å°æ‰€æœ‰æ•°æ®ç±»å‹ä¿¡æ¯
    
    å‚æ•°:
        file_path: HDF5æ–‡ä»¶è·¯å¾„
        show_data: æ˜¯å¦æ˜¾ç¤ºæ•°æ®æ ·ä¾‹
        max_depth: æœ€å¤§é€’å½’æ·±åº¦ï¼ŒNoneè¡¨ç¤ºæ— é™åˆ¶
    """
    print(f"\n{'='*60}")
    print(f"HDF5æ–‡ä»¶: {file_path}")
    print(f"{'='*60}\n")
    
    with h5py.File(file_path, 'r') as f:
        # æ‰“å°æ–‡ä»¶çº§åˆ«çš„å±æ€§
        if f.attrs:
            print("ğŸ“„ æ–‡ä»¶å±æ€§:")
            for key, val in f.attrs.items():
                print(f"  - {key}: {val}")
            print()
        
        def visit_func(name, obj, depth=0):
            """è®¿é—®å‡½æ•°"""
            if max_depth is not None and depth > max_depth:
                return
            
            indent = depth
            
            if isinstance(obj, h5py.Group):
                print_group_info(name, obj, indent)
            elif isinstance(obj, h5py.Dataset):
                print_dataset_info(name, obj, indent)
            
            print()  # ç©ºè¡Œåˆ†éš”
        
        # éå†æ‰€æœ‰å¯¹è±¡
        def recursive_visit(group, depth=0):
            """é€’å½’è®¿é—®æ‰€æœ‰ç»„å’Œæ•°æ®é›†"""
            if max_depth is not None and depth > max_depth:
                return
            
            for key in group.keys():
                obj = group[key]
                full_name = f"{group.name}/{key}" if group.name != '/' else f"/{key}"
                
                if isinstance(obj, h5py.Group):
                    print_group_info(full_name, obj, depth)
                    print()
                    recursive_visit(obj, depth + 1)
                elif isinstance(obj, h5py.Dataset):
                    print_dataset_info(full_name, obj, depth)
                    print()
        
        recursive_visit(f, 0)


def list_keys(file_path, group_path='/'):
    """
    åˆ—å‡ºæŒ‡å®šç»„ä¸­çš„æ‰€æœ‰é”®
    
    å‚æ•°:
        file_path: HDF5æ–‡ä»¶è·¯å¾„
        group_path: ç»„è·¯å¾„ï¼Œé»˜è®¤ä¸ºæ ¹ç›®å½•
    """
    print(f"\n{'='*60}")
    print(f"HDF5æ–‡ä»¶: {file_path}")
    print(f"ç»„è·¯å¾„: {group_path}")
    print(f"{'='*60}\n")
    
    with h5py.File(file_path, 'r') as f:
        if group_path in f:
            group = f[group_path]
            print(f"ç»„ '{group_path}' ä¸­çš„é”®:")
            for key in group.keys():
                obj = group[key]
                if isinstance(obj, h5py.Group):
                    print(f"  ğŸ“ {key} (ç»„)")
                elif isinstance(obj, h5py.Dataset):
                    print(f"  ğŸ“Š {key} (æ•°æ®é›†, å½¢çŠ¶: {obj.shape}, ç±»å‹: {obj.dtype})")
        else:
            print(f"é”™è¯¯: ç»„ '{group_path}' ä¸å­˜åœ¨")


def get_dataset_info(file_path, dataset_path):
    """
    è·å–ç‰¹å®šæ•°æ®é›†çš„è¯¦ç»†ä¿¡æ¯
    
    å‚æ•°:
        file_path: HDF5æ–‡ä»¶è·¯å¾„
        dataset_path: æ•°æ®é›†è·¯å¾„
    """
    print(f"\n{'='*60}")
    print(f"HDF5æ–‡ä»¶: {file_path}")
    print(f"æ•°æ®é›†è·¯å¾„: {dataset_path}")
    print(f"{'='*60}\n")
    
    with h5py.File(file_path, 'r') as f:
        if dataset_path in f:
            dataset = f[dataset_path]
            if isinstance(dataset, h5py.Dataset):
                print_dataset_info(dataset_path, dataset, 0)
                
                # æ˜¾ç¤ºæ•°æ®çš„ç»Ÿè®¡ä¿¡æ¯ï¼ˆå¦‚æœæ˜¯æ•°å€¼ç±»å‹ï¼‰
                if np.issubdtype(dataset.dtype, np.number):
                    data = dataset[...]
                    print(f"\nç»Ÿè®¡ä¿¡æ¯:")
                    print(f"  - æœ€å°å€¼: {np.min(data)}")
                    print(f"  - æœ€å¤§å€¼: {np.max(data)}")
                    print(f"  - å¹³å‡å€¼: {np.mean(data)}")
                    print(f"  - æ ‡å‡†å·®: {np.std(data)}")
            else:
                print(f"'{dataset_path}' ä¸æ˜¯æ•°æ®é›†ï¼Œè€Œæ˜¯ä¸€ä¸ªç»„")
        else:
            print(f"é”™è¯¯: æ•°æ®é›† '{dataset_path}' ä¸å­˜åœ¨")


def main():
    parser = argparse.ArgumentParser(
        description='è¯»å–HDF5æ–‡ä»¶çš„æ•°æ®ç±»å‹å’Œç»“æ„ä¿¡æ¯',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # æŸ¥çœ‹æ•´ä¸ªæ–‡ä»¶çš„ç»“æ„
  python read_hdf5_types.py data.hdf5
  
  # åªåˆ—å‡ºæ ¹ç›®å½•çš„é”®
  python read_hdf5_types.py data.hdf5 --list-keys
  
  # åˆ—å‡ºç‰¹å®šç»„çš„é”®
  python read_hdf5_types.py data.hdf5 --list-keys --group /observations
  
  # æŸ¥çœ‹ç‰¹å®šæ•°æ®é›†çš„ä¿¡æ¯
  python read_hdf5_types.py data.hdf5 --dataset /observations/qpos
  
  # é™åˆ¶æ˜¾ç¤ºæ·±åº¦
  python read_hdf5_types.py data.hdf5 --max-depth 2
        """
    )
    
    parser.add_argument('file', type=str, help='HDF5æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--list-keys', action='store_true', 
                        help='ä»…åˆ—å‡ºé”®ï¼Œä¸æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯')
    parser.add_argument('--group', type=str, default='/',
                        help='æŒ‡å®šè¦åˆ—å‡ºçš„ç»„è·¯å¾„ (é…åˆ --list-keys ä½¿ç”¨)')
    parser.add_argument('--dataset', type=str,
                        help='æ˜¾ç¤ºç‰¹å®šæ•°æ®é›†çš„è¯¦ç»†ä¿¡æ¯')
    parser.add_argument('--max-depth', type=int,
                        help='æœ€å¤§æ˜¾ç¤ºæ·±åº¦')
    parser.add_argument('--show-data', action='store_true',
                        help='æ˜¾ç¤ºæ•°æ®æ ·ä¾‹')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not Path(args.file).exists():
        print(f"é”™è¯¯: æ–‡ä»¶ '{args.file}' ä¸å­˜åœ¨")
        return
    
    try:
        if args.dataset:
            # æ˜¾ç¤ºç‰¹å®šæ•°æ®é›†çš„ä¿¡æ¯
            get_dataset_info(args.file, args.dataset)
        elif args.list_keys:
            # ä»…åˆ—å‡ºé”®
            list_keys(args.file, args.group)
        else:
            # æ˜¾ç¤ºå®Œæ•´çš„æ–‡ä»¶ç»“æ„
            explore_hdf5(args.file, args.show_data, args.max_depth)
    except Exception as e:
        print(f"é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()

    '''
    # æŸ¥çœ‹æ•´ä¸ªæ–‡ä»¶çš„ç»“æ„
    python read_hdf5_types.py your_file.hdf5

    # åªåˆ—å‡ºæ ¹ç›®å½•çš„é”®
    python read_hdf5_types.py your_file.hdf5 --list-keys

    # åˆ—å‡ºobservationsç»„çš„é”®
    python read_hdf5_types.py your_file.hdf5 --list-keys --group /observations

    # æŸ¥çœ‹ç‰¹å®šæ•°æ®é›†çš„è¯¦ç»†ä¿¡æ¯
    python read_hdf5_types.py your_file.hdf5 --dataset /observations/qpos

    # é™åˆ¶æ˜¾ç¤ºæ·±åº¦ä¸º2å±‚
    python read_hdf5_types.py your_file.hdf5 --max-depth 2
    '''